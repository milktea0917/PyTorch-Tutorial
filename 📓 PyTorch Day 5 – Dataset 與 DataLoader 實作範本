# âœ… 1. ä½¿ç”¨ TensorDataset å»ºç«‹è³‡æ–™é›†

import torch
from torch.utils.data import TensorDataset, DataLoader

# æ¨¡æ“¬è³‡æ–™ï¼ˆfeatures èˆ‡ labelsï¼‰
X = torch.linspace(0, 10, steps=100).reshape(-1, 1)
y = 2 * X + 1 + 0.5 * torch.randn_like(X)  # åŠ ä¸€äº› noise

# å»ºç«‹ Dataset
dataset = TensorDataset(X, y)

# å»ºç«‹ DataLoader
loader = DataLoader(dataset, batch_size=10, shuffle=True)

# æŸ¥çœ‹ä¸€å€‹ batch
for batch_X, batch_y in loader:
    print("Batch X:", batch_X)
    print("Batch y:", batch_y)
    break

# âœ… 2. è‡ªå®šç¾© Dataset é¡åˆ¥

from torch.utils.data import Dataset

class MyDataset(Dataset):
    def __init__(self):
        self.data = torch.arange(100).float()
        
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        x = self.data[idx]
        y = x * 2 + 3
        return x, y

my_dataset = MyDataset()
my_loader = DataLoader(my_dataset, batch_size=8, shuffle=False)

for x, y in my_loader:
    print("x:", x)
    print("y:", y)
    break
âœ… 3. åŠ å…¥ GPU æ”¯æ´ï¼šData + Model

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# æ¨¡å‹
import torch.nn as nn
model = nn.Linear(1, 1).to(device)

# å–®å€‹ batch forward
for batch_X, batch_y in loader:
    batch_X = batch_X.to(device)
    batch_y = batch_y.to(device)
    
    preds = model(batch_X)
    print("Output:", preds)
    break

# âœ… 4. DataLoader å°æŠ€å·§ï¼šè¨­å®šåƒæ•¸

loader = DataLoader(
    dataset,
    batch_size=16,
    shuffle=True,
    num_workers=2,   # å¤šåŸ·è¡Œç·’è³‡æ–™é è¼‰ï¼ˆColab ä¸Šè«‹ç”¨ 0 æˆ– 2ï¼‰
    pin_memory=True # CPU â†’ GPU è¼ƒå¿«
)

# âœ… 5. æŒ‘æˆ°ç·´ç¿’ï¼ˆOptionalï¼‰
## å¯¦ä½œä¸€å€‹ Datasetï¼Œå…§å®¹ç‚ºå¹³æ–¹æ ¹èˆ‡å¹³æ–¹æ•¸çš„å°ç…§è¡¨ï¼ˆä¾‹å¦‚ 0~99ï¼‰
###version1
X = torch.linspace(0, 99, steps=100).reshape(-1, 1)
y = X ** 2
dataset = TensorDataset(X, y)

###version2
class MyDataset(Dataset):
    def __init__(self):
        self.data = torch.arange(100).float()
        
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        x = self.data[idx]
        y = x ** 2 
        return x, y

## å»ºç«‹ä¸€å€‹ DataLoaderï¼Œä½¿ç”¨ batch_size=20ï¼Œä¸¦åˆ—å‡ºå‰ 2 å€‹ batch çš„è³‡æ–™
dataloader = DataLoader(dataset, batch_size=20, shuffle=True, num_workers=2, pin_memory=True)
dataloader_iter = iter(dataloader)

for iteration, (batch_X, batch_y) in enumerate(dataloader_iter):
  if iteration > 1:
    break

## å˜—è©¦èˆ‡ä¸€å€‹ç°¡å–®ç·šæ€§æ¨¡å‹çµåˆï¼Œå°‡ batch è³‡æ–™è¼¸å…¥ä¸¦è¼¸å‡ºé æ¸¬çµæœ
import torch
import torch.nn

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = nn.Linear(1,1).to(device)
criterion = nn.MSELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # è¨˜å¾—è¦å¤šoptimizer
epochs = 3

for epoch in range(epochs):

  # for steps, (batch_X, batch_y) in enumerate(dataloader_iter): 
  # â†’ dataloader_iter éŒ¯èª¤ â†’ æ¯æ¬¡ epoch éƒ½å¾åŒä¸€å€‹åœ°æ–¹æ¥è‘—è®€ â†’ å¾ˆå¿«å°±è®€å®Œï¼Œå†ä¹Ÿæ‹¿ä¸åˆ°æ–°è³‡æ–™ â†’ ä¹‹å¾Œè¨“ç·´ loop æœƒç©ºè½‰ï¼ 
  for batch_X, batch_y in dataloader:
    batch_X = batch_X.to(device)
    batch_y = batch_y.to(device)

    preds = model(batch_X)
    loss = criterion(preds, batch_y)

    optimizer.zero_grad() # å…ˆæ¸…ç©ºGradient
    loss.backward() # ç®—loss
    optimizer.step() # èª¿æ•´æ¨¡å‹åƒæ•¸
    # print("preds:", preds)
    # print("loss:", loss)

  print(f"[Epoch {epoch+1}] Loss: {loss.item():.4f}")

# ğŸ“Œ å°æé†’ï¼š
## æ¯æ¬¡å¾ DataLoader å–å‡ºçš„ batch éƒ½æ˜¯éš¨æ©Ÿçš„ï¼ˆè‹¥æœ‰ shuffle=Trueï¼‰
## Dataset å¿…é ˆå¯¦ä½œä¸‰å€‹æ–¹æ³•ï¼š__init__ã€__len__ã€__getitem__
## åœ¨ GPU è¨“ç·´æ™‚è¨˜å¾— .to(device) æ¬ç§»è³‡æ–™

# âœ… 1. ç¢ºèª PyTorch æ˜¯å¦å·²å®‰è£ï¼ˆColab å·²é è£ï¼‰
import torch
print(torch.__version__)
print("CUDA available:", torch.cuda.is_available())

# âœ… 2. å»ºç«‹èˆ‡æ“ä½œ Tensor
# å»ºç«‹ Tensor
x = torch.empty(3, 4)         # æœªåˆå§‹åŒ–
y = torch.rand(3, 4)          # éš¨æ©Ÿåˆå§‹åŒ–
z = torch.zeros(3, 4)         # å…¨ç‚º 0
o = torch.ones(3, 4)          # å…¨ç‚º 1
print("x:\n", x)
print("y:\n", y)

# âœ… 3. åŸºæœ¬é‹ç®—
a = torch.rand(2, 2)
b = torch.rand(2, 2)

print("a + b =\n", a + b)              # æ™®é€šåŠ æ³•
print("a - b =\n", torch.sub(a, b))    # ä½¿ç”¨å‡½æ•¸
print("a * b =\n", a * b)              # element-wise ä¹˜æ³•
print("a @ b.T =\n", a @ b.T)          # çŸ©é™£ä¹˜æ³•

# âœ… 4. Tensor æ“ä½œ
t = torch.rand(4, 3)
print("åŸå§‹å½¢ç‹€:", t.shape)

t_reshaped = t.view(2, 6)
print("reshape å¾Œ:", t_reshaped.shape)
print("è½‰ç‚º numpy:", t.numpy())

# âœ… 5. Tensor èˆ‡ GPU
if torch.cuda.is_available():
    device = torch.device("cuda")
    x = torch.rand(2, 2).to(device)
    print("Tensor åœ¨ GPU ä¸Šé‹è¡Œ:", x)
else:
    print("ç›®å‰ç„¡ GPU å¯ä½¿ç”¨ï¼Œä»å¯ç”¨ CPU")

# âœ… 6. æŒ‘æˆ°ç·´ç¿’ï¼ˆOptionalï¼‰

# å»ºç«‹ä¸€å€‹ 10x10 çš„ Tensor ä¸¦å¡«å…¥ 0 åˆ° 99

## version1ï¼š
data = [i for i in range(100)]
data = torch.tensor(data).view(10,10)

## version2ï¼š(more PyTorch-native)
data = torch.arange(100).view(10, 10)

# å°ä»»æ„ Tensor è¨ˆç®— row-wise æœ€å¤§å€¼èˆ‡å…¶ç´¢å¼•

## version1ï¼š
for i in range(data.size(0)):
  print(f"max: {max(data[i])}; index: {torch.argmax(data[i])}")

## version2ï¼š(better version)
max_vals, max_indices = torch.max(data, dim=1)
for i in range(data.size(0)):
    print(f"Row {i} -> max: {max_vals[i]}, index: {max_indices[i]}")

# ä½¿ç”¨ GPU ä¾†å®Œæˆä¸€æ¬¡ç°¡å–®é‹ç®—

## version1ï¼š
data.to(device)

## version2ï¼š(ğŸ‘€ å°æé†’ï¼šé€™ä¸€è¡Œ data.to(device) ä¸¦æ²’æœ‰æ”¹è®Š data çš„å…§å®¹ï¼Œå› ç‚º .to() æ˜¯ä¸æœƒåŸåœ°ä¿®æ”¹çš„ï¼Œå®ƒæœƒå›å‚³ä¸€å€‹æ–°çš„ tensorã€‚)
data = data.to(device)

import torch
import torch.nn as nn
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import torch.nn.functional as F
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import numpy as np
import os
import re
import matplotlib.pyplot as plt
from torch.utils.tensorboard import SummaryWriter

# prepare MNIST Data
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

train_data = datasets.MNIST(root="./data", train=True, transform=transform, download=True)
test_data = datasets.MNIST(root="./data", train=False, transform=transform)

train_loader = DataLoader(train_data, batch_size=64, shuffle=True)
test_loader = DataLoader(test_data, batch_size=1000)

# Build Model
class MLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(28*28, 256)
        self.dropout = nn.Dropout(0.3)
        self.fc2 = nn.Linear(256, 10)

    def forward(self, x):
        x = x.view(-1, 28*28)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x
    
class CNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)
        self.dropout = nn.Dropout(0.25)
        self.fc1 = nn.Linear(9216, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2)
        x = self.dropout(x)
        x = torch.flatten(x, 1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

device = torch.device("cuda:1" if torch.cuda.is_available() else "cpu")
# model = MLP().to(device)
model = CNN().to(device) # CNN perfroms better in this case

# Optimizer
criterion = nn.CrossEntropyLoss()
# optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)
optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)
# optimizer = torch.optim.RMSprop(model.parameters(), lr = 0.01)

# train loop
os.makedirs("model_checkpoint", exist_ok=True)  # for saving model_checkpoint
os.makedirs("runs", exist_ok=True)  # for saving tensorboard
writer = SummaryWriter(log_dir="runs/MNIST_CNN")

epochs = 20
train_losses = []

for epoch in range(epochs):
    model.train()
    batch_loss = 0
    for batch_X, batch_y in train_loader:
        batch_X, batch_y = batch_X.to(device), batch_y.to(device)

        logits = model(batch_X)
        loss = criterion(logits, batch_y)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        batch_loss += loss.item()

    avg_loss = batch_loss / len(train_loader)
    
   # if better than the exists checkpoint, then save 
    if len(train_losses)==0 or avg_loss < train_losses[-1]:
        torch.save({'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'loss': loss.item()}, f"model_checkpoint/checkpoint_{epoch}.pt")
    
    print(f"[Epoch {epoch+1}] Loss: {avg_loss:.4f}")
    train_losses.append(avg_loss)
    writer.add_scalar('Loss/train', avg_loss, epoch)

# draw loss curve
plt.plot(train_losses, label='train_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss')
plt.legend()
plt.savefig("loss_curve_CNN.png")
plt.close()

# evaluation
model_checkpoint_path = "./model_checkpoint/"
assert os.path.exists(model_checkpoint_path) == True
model_list = os.listdir(model_checkpoint_path)
model_list = sorted(
    [f for f in model_list if f.startswith("checkpoint_")],
    key=lambda x:int(re.findall(r"\d+", x)[0])
)
model_evaluate_result = {}

for i in model_list:

    correct = 0
    total = 0
    print(f"Loading model checkpoint: {i}")
    checkpoint = torch.load(os.path.join(model_checkpoint_path, i))
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()

    with torch.no_grad():
        for batch_X, batch_y in test_loader:
            batch_X, batch_y = batch_X.to(device), batch_y.to(device)
            logits = model(batch_X)
            pred = torch.argmax(logits, dim=1)
            correct += (pred==batch_y).sum().item()
            total += batch_y.size(0)

    acc = correct / total
    print(f"Test Accuracy: {acc * 100:.2f}% in model_checkpoint:{i}")
    writer.add_scalar('Accuracy/test', acc, int(re.findall(r"\d+", i)[0]))
    model_evaluate_result[i] = acc

writer.close()

# find the best model from evaluate result
best_model = max(model_evaluate_result, key=model_evaluate_result.get)
best_acc = model_evaluate_result[best_model]

# rename
best_model_path = os.path.join(model_checkpoint_path, best_model)
best_model_rename_path = os.path.join(model_checkpoint_path, 'best_model.pt')

if os.path.exists(best_model_rename_path):
    print(f"There exists a best_model, the script is gonig to replace.")
    os.remove(best_model_rename_path)

os.rename(best_model_path, best_model_rename_path)
print(f"✅ Renamed best model '{best_model}' → 'best_model.pt' (Acc: {best_acc:.4f})")

# MLP + Adam --> 0.9539
# MLP + SGD --> 0.9753
# MLP + RMSProp --> 0.9534
# CNN + SGD --> 0.9888
        
# evaluation best
model_checkpoint_path = "./model_checkpoint/"
assert os.path.exists(model_checkpoint_path) == True
model_list = os.listdir(model_checkpoint_path)
model_list = sorted(
    [f for f in model_list if f.startswith("CNN_")],
    key=lambda x:int(re.findall(r"\d+", x)[0])
)
model_evaluate_result = {}

for i in model_list:

    correct = 0
    total = 0
    all_preds = []
    all_labels = []
    print(f"Loading model checkpoint: {i}")
    checkpoint = torch.load(os.path.join(model_checkpoint_path, i))
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()

    with torch.no_grad():
        for batch_X, batch_y in test_loader:
            
            batch_X, batch_y = batch_X.to(device), batch_y.to(device)
            logits = model(batch_X)
            pred = torch.argmax(logits, dim=1)
            correct += (pred==batch_y).sum().item()
            total += batch_y.size(0)

            # confusion matrix data
            all_preds.extend(pred.cpu().numpy())
            all_labels.extend(batch_y.cpu().numpy())
    
    # confusion matrix
    cm = confusion_matrix(all_labels, all_preds)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(10)))
    disp.plot(cmap=plt.cm.Blues)
    plt.title(f"Confusion Matrix: {i}")
    plt.savefig(f"confusion_matrix_{i}.png")
    plt.close()

    acc = correct / total
    print(f"Test Accuracy: {acc * 100:.2f}% in model_checkpoint:{i}")
    model_evaluate_result[i] = acc
